date:: [[Jul 26th, 2006]]
archive-location:: world
extra:: Publisher: Society for Industrial and Applied Mathematics
doi:: 10.1137/S0363012903437976
title:: @Individual Q-Learning in Normal Form Games
item-type:: [[journalArticle]]
access-date:: 2022-12-25T10:56:34Z
rights:: Copyright © 2005 Society for Industrial and Applied Mathematics
original-title:: Individual Q-Learning in Normal Form Games
language:: en
url:: https://epubs.siam.org/doi/10.1137/S0363012903437976
publication-title:: SIAM Journal on Control and Optimization
authors:: [[David S. Leslie]], [[E. J. Collins]]
library-catalog:: epubs.siam.org
links:: [Local library](zotero://select/library/items/DX5IF55V), [Web library](https://www.zotero.org/users/7448055/items/DX5IF55V)

- [[Abstract]]
	- The single-agent multi-armed bandit problem can be solved by an agent that learns the values of each action using reinforcement learning. However, the multi-agent version of the problem, the iterated normal form game, presents a more complex challenge, since the rewards available to each agent depend on the strategies of the others. We consider the behavior of value-based learning agents in this situation, and show that such agents cannot generally play at a Nash equilibrium, although if smooth best responses are used, a Nash distribution can be reached. We introduce a particular value-based learning algorithm, which we call individual Q-learning, and use stochastic approximation to study the asymptotic behavior, showing that strategies will converge to Nash distribution almost surely in 2-player zero-sum games and 2-player partnership games. Player-dependent learning rates are then considered, and it is shown that this extension converges in some games for which many algorithms, including the basic algorithm initially considered, fail to converge.
- [[Attachments]]
	- [Leslie and Collins - 2006 - Individual Q-Learning in Normal Form Games.pdf](zotero://select/library/items/37W8LRRU) {{zotero-imported-file 37W8LRRU, "Leslie and Collins - 2006 - Individual Q-Learning in Normal Form Games.pdf"}}
	- [Snapshot](https://epubs.siam.org/doi/epdf/10.1137/S0363012903437976) {{zotero-imported-file GNSIDQNL, "S0363012903437976.html"}}
- date:: [[Jul 26th, 2006]]
  archive-location:: world
  extra:: Publisher: Society for Industrial and Applied Mathematics
  doi:: 10.1137/S0363012903437976
  title:: @Individual Q-Learning in Normal Form Games
  item-type:: [[journalArticle]]
  access-date:: 2022-12-25T10:56:34Z
  rights:: Copyright © 2005 Society for Industrial and Applied Mathematics
  original-title:: Individual Q-Learning in Normal Form Games
  language:: en
  url:: https://epubs.siam.org/doi/10.1137/S0363012903437976
  publication-title:: SIAM Journal on Control and Optimization
  authors:: [[David S. Leslie]], [[E. J. Collins]]
  library-catalog:: epubs.siam.org
  links:: [Local library](zotero://select/library/items/DX5IF55V), [Web library](https://www.zotero.org/users/7448055/items/DX5IF55V)
- [[Abstract]]
	- The single-agent multi-armed bandit problem can be solved by an agent that learns the values of each action using reinforcement learning. However, the multi-agent version of the problem, the iterated normal form game, presents a more complex challenge, since the rewards available to each agent depend on the strategies of the others. We consider the behavior of value-based learning agents in this situation, and show that such agents cannot generally play at a Nash equilibrium, although if smooth best responses are used, a Nash distribution can be reached. We introduce a particular value-based learning algorithm, which we call individual Q-learning, and use stochastic approximation to study the asymptotic behavior, showing that strategies will converge to Nash distribution almost surely in 2-player zero-sum games and 2-player partnership games. Player-dependent learning rates are then considered, and it is shown that this extension converges in some games for which many algorithms, including the basic algorithm initially considered, fail to converge.
- [[Attachments]]
	- [Leslie and Collins - 2006 - Individual Q-Learning in Normal Form Games.pdf](zotero://select/library/items/37W8LRRU) {{zotero-imported-file 37W8LRRU, "Leslie and Collins - 2006 - Individual Q-Learning in Normal Form Games.pdf"}}
	- [Snapshot](https://epubs.siam.org/doi/epdf/10.1137/S0363012903437976) {{zotero-imported-file GNSIDQNL, "S0363012903437976.html"}}