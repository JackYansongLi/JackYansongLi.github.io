title:: @The Dynamics of Reinforcement Learning in Cooperative Multiagent Systems
pages:: 7
item-type:: [[journalArticle]]
original-title:: The Dynamics of Reinforcement Learning in Cooperative Multiagent Systems
language:: en
authors:: [[Caroline Claus]], [[Craig Boutilier]]
library-catalog:: Zotero
links:: [Local library](zotero://select/library/items/63HI8Q5B), [Web library](https://www.zotero.org/users/7448055/items/63HI8Q5B)

- [[Abstract]]
	- Reinforcement learning can provide a robust and natural means for agents to learn how to coordinate their action choices in multiagent systems. We examine some of the factors that can inﬂuence the dynamics of the learning process in such a setting. We ﬁrst distinguish reinforcement learners that are unaware of (or ignore) the presence of other agents from those that explicitly attempt to learn the value of joint actions and the strategies of their counterparts. We study (a simple form of) Q-learning in cooperative multiagent systems under these two perspectives, focusing on the inﬂuence of that game structure and exploration strategies on convergence to (optimal and suboptimal) Nash equilibria. We then propose alternative optimistic exploration strategies that increase the likelihood of convergence to an optimal equilibrium.
- [[Attachments]]
	- [Claus and Boutilier - The Dynamics of Reinforcement Learning in Cooperat.pdf](https://www.aaai.org/Papers/AAAI/1998/AAAI98-106.pdf) {{zotero-imported-file UXGN9RJV, "Claus and Boutilier - The Dynamics of Reinforcement Learning in Cooperat.pdf"}}