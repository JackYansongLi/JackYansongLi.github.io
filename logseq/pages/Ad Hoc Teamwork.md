- ## AHT Problem Formulation: formulated by input, output, and assumptions.
	- Input: ((644d94ff-effc-425d-8f85-b103583bd564))
		- Domain Knowledge: Transition Kernel: $P \colon S \times A \rightarrow S$, Reward Function: $R \colon S \times A \rightarrow [0,1]$, An (possibly incomplete) list of attributes of each agents $\left( R_i, \Omega_i,A_i \right)$. A description of the learner's abilities?
	- Output: ((644d968a-687e-4e56-9fe5-37ff63c19346))
		- Output: $\pi \colon S \rightarrow A$
	- Assumptions: No prior coordination, No control over teammates, Collaborative
- ## Subtasks in AHT
	- ### [[Knowledge Representation]]
		- ((644d99de-4c29-45ef-aaa0-5da3c96c42bd))
	- ### [[Modeling Teammates]]
		- ((644d9a1f-c398-4081-b971-96376d29e3b8))
	- ### [[Action Selection]]
		- ((644d9a63-ff29-4b7a-9f27-b068b3d2646b))
	- ### [[Adapting to Changes]]
		- ((644d9a8d-3554-4e3a-9558-c9980d3e5b5a))
- ## Additional Remark
	- ((644ed11d-b116-490d-9b98-19a62542df73))
	- It is also common to assume uniform priors across types and type parameters [6] [[@An Empirical Study on the Practical Impact of Prior Beliefs over Policy Types]] .
	- ((644ee8cc-4e76-41fd-812d-f540921e69a6))
- TODO ((644d9f72-bab2-4231-ac60-9108be52a305)) [[@Adding Influencing Agents to a Flock]]