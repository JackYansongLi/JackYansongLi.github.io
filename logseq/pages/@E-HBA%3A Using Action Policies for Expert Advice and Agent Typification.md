links:: [Local library](zotero://select/library/items/WLBBVC5S), [Web library](https://www.zotero.org/users/7448055/items/WLBBVC5S)
authors:: [[Stefano V. Albrecht]], [[Jacob W. Crandall]], [[Subramanian Ramamoorthy]]
tags:: [[Computer Science - Artificial Intelligence]], [[Computer Science - Multiagent Systems]]
date:: [[Jul 23rd, 2019]]
item-type:: [[preprint]]
title:: @E-HBA: Using Action Policies for Expert Advice and Agent Typification

- [[Abstract]]
	- Past research has studied two approaches to utilise predefined policy sets in repeated interactions: as experts, to dictate our own actions, and as types, to characterise the behaviour of other agents. In this work, we bring these complementary views together in the form of a novel meta-algorithm, called Expert-HBA (E-HBA), which can be applied to any expert algorithm that considers the average (or total) payoff an expert has yielded in the past. E-HBA gradually mixes the past payoff with a predicted future payoff, which is computed using the type-based characterisation. We present results from a comprehensive set of repeated matrix games, comparing the performance of several well-known expert algorithms with and without the aid of E-HBA. Our results show that E-HBA has the potential to significantly improve the performance of expert algorithms.
- [[Attachments]]
	- [arXiv.org Snapshot](https://arxiv.org/abs/1907.09810) {{zotero-imported-file WL45CNNI, "1907.html"}}
	- [arXiv Fulltext PDF](https://arxiv.org/pdf/1907.09810.pdf) {{zotero-imported-file 2DIRZG4V, "Albrecht et al. - 2019 - E-HBA Using Action Policies for Expert Advice and.pdf"}}