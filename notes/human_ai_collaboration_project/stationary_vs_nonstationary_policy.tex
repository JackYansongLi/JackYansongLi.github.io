\documentclass{article}
\usepackage[english]{babel}
\usepackage{amsmath,amssymb,latexsym}

%%%%%%%%%% Start TeXmacs macros
\newcommand{\tmop}[1]{\ensuremath{\operatorname{#1}}}
\newenvironment{proof}{\noindent\textbf{Proof\ }}{\hspace*{\fill}$\Box$\medskip}
\newtheorem{lemma}{Lemma}
%%%%%%%%%% End TeXmacs macros

\begin{document}

\begin{lemma}
  \label{lem:argmax}If $a = \tmop{argmax}_{x \in \mathcal{X}}  [f (x) + g
  (x)]$ and $b = \tmop{argmax}_{x \in \mathcal{X}} f (x)$, then, $f (b) \geq f
  (a)$ and
  \[ f (b) - f (a) \leq g (a) - g (b) . \]
\end{lemma}

\begin{proof}
  By definition,
  \[ f (a) + g (a) \geq f (x) + g (x) \]
  for all $x \in \mathcal{X}$. Let $x = b$, we have
  \[ f (a) + g (a) \geq f (b) + g (b) . \]
  Rearranging the above formula gives us
  \[ f (b) - f (a) \leq g (a) - g (b) . \]
  Similarly, by definition
  \[ f (b) \geq f (x) \]
  for all $x \in \mathcal{X}$. Let $x = a$ gives $f (b) \geq f (a)$
\end{proof}

It is well-known that an optimal policies for an infinite horizon MDP is
stationary, i.e., the policy can be independent of time. In the following, we
will show that when the time horizon is large enough, the cumulative reward of
a finite MDP that adopts an optimal stationary policy for an infinite
counterpart is close to the cumulative reward of a finite MDP that adopts an
non-stationary policy of its own.

An optimal stationary policy $(\mu_{\infty}, \pi_{\infty})$ for an infinite
counterpart is defined as
\[ (\mu_{\infty}, \pi_{\infty}) = \underset{(\mu, \pi) \in \mathcal{U} \times
   \Pi}{\tmop{argmax}} \quad \mathbb{E}_{a^k_t \sim \mu (s^k_t, t), b^k_t \sim
   \pi (s^k_t, t)} \left[ \sum_{t = 1}^{\infty} \gamma^{t - 1} r (s^k_t,
   a^k_t, b^k_t) \mid a^k_1 = a_1 \right] \]
and an optimal nonstationary policy $(\mu^{\ast}, \pi^{\ast})$ is defined as
\[ (\mu^{\ast}, \pi^{\ast}) = \underset{(\mu, \pi) \in \mathcal{U} \times
   \Pi}{\tmop{argmax}} \quad \mathbb{E}_{a^k_t \sim \mu (s^k_t, t), b^k_t \sim
   \pi (s^k_t, t)} \left[ \sum_{t = 1}^H \gamma^{t - 1} r (s^k_t, a^k_t,
   b^k_t) \mid a^k_1 = a_1 \right] \]
Thus, applying Lemma \ref{lem:argmax}, we have $V (\mu^{\ast}, \pi^{\ast})
\geq V (\mu_{\infty}, \pi_{\infty})$ and
\[ V (\mu^{\ast}, \pi^{\ast}) - V (\mu_{\infty}, \pi_{\infty}) \leq g
   (\mu_{\infty}, \pi_{\infty}) - g (\mu^{\ast}, \pi^{\ast}), \]
where
\[ g (\mu, \pi) \triangleq \mathbb{E}_{a^k_t \sim \mu (s^k_t, t), b^k_t \sim
   \pi (s^k_t, t)} \left[ \sum_{t = H + 1}^{\infty} \gamma^{t - 1} r (s^k_t,
   a^k_t, b^k_t) \mid a^k_1 = a_1 \right] . \]
Since $r : S \times A^2 \rightarrow [0, 1]$, we have
\[ V (\mu^{\ast}, \pi^{\ast}) - V (\mu_{\infty}, \pi_{\infty}) \leq 2 \sum_{t
   = H + 1}^{\infty} \gamma^{t - 1} = \frac{\gamma^H}{1 - \gamma} . \]
The distance $\gamma^H / (1 - \gamma)$ will be small if $H$ is large.

\

\

\end{document}
