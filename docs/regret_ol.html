<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns:x="https://www.texmacs.org/2002/extensions" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Jack Yansong Li's Website</title>
    <meta content="TeXmacs 2.1.2" name="generator"></meta>
    <link href="../resources/notes-base.css" rel="stylesheet" type="text/css"></link>
    <link href="../resources/blog-icon.png" rel="icon"></link>
    <script language="javascript" src="../resources/highlight.pack.js" defer></script>
    <script language="javascript" src="../resources/notes-base.js" defer></script>
    <script language="javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </head>
  <body>
    <div class="notes-header">
      <p>
        <img class="image" src="../resources/texmacs-blog-transparent.png" width="28.116784"></img><span style="margin-left: 2pt"></span><a href="./main.html">[main]</a><em
        class="notes-header-name">Jack Yansong Li's Website</em>
      </p>
    </div>
    <p>
      <a id="auto-1"></a>
    </p>
    <h1>Why using regret in online learning<span style="margin-left: 1em"></span></h1>
    <p>
      Regret analysis is broadly adopted in learning with online interactions.
      However, why using regret minimization instead of cost minimization as
      in other learning tasks such as batch learning? In this short note, we
      will give an example that by minimizing the regret, the learner gets a
      better reward.
    </p>
    <h2 id="auto-2">1.<span style="margin-left: 1em"></span>Worst-case cost and worst-case regret
    cost<span style="margin-left: 1em"></span></h2>
    <p>
      Consider the function \(g\) defined as \(g (x) \triangleq
      \underset{y}{\max .} f (x, y)\), where \(f\) is an arbitrary function.
      The optimization problem defined as
    </p>
    <table width="100%">
      <tr>
        <td align="center" width="100%">\(\displaystyle \underset{x}{\min .} \quad g (x)
        \equiv \underset{x}{\min .} \quad
\underset{y}{\max .} f (x, y)\)</td>
        <td align="right">(1)</td>
      </tr>
    </table>
    <p>
      can be viewed as a worst-case optimization problem, and \(g (x)\) is
      called <i>worst-case cost</i>.
    </p>
    <p>
      Let's consider a scenario where we have \(f (x, y)\) that represents the
      time required to drive a car from one location to another given policy
      \(x\) and environment \(y\). In this context, \(x\) represents the
      driver's driving pattern, which encompass decisions like adjusting
      speed, selecting lanes (left or right), and other driving strategies. On
      the other hand, \(y\) represents a binary condition indicating whether
      it's currently raining (\(y = 1\)) or not (\(y = 0\)). Together, this
      function captures how the driver's decisions and weather conditions
      collectively impact the time it takes for the journey.
    </p>
    <p>
      It's a widely acknowledged fact that driving takes more time on days
      when it's raining. Thus, \(\underset{y}{\max .} f (x, y) = f (x, 1)\).
      By definition, the function \(g (x)\) currently represents the time
      required for driving on rainy days.
    </p>
    <p>
      Now, define \(g' (x) \triangleq \underset{y}{\max} \left( f (x, y) -
      \underset{x'}{\min} f
(x', y) \right)\). We call \(g' (x)\) the
      <i>worst-case regret cost</i>. Unlike worst-case cost, the regret cost
      measures the maximum achievement <b>it can be improved</b> in the past
      days. For example, if a driver cannot drive in the rainy day due to
      rheumatoid arthritis. Then there is no difference between \(f (x,
      \operatorname{rain})\) and \(f (x', \operatorname{rain})\) for any \(x\)
      and \(x'\), which makes \(g' (x) = 0\). No regret at all! Because
      nothing can be improved in the worst-case.
    </p>
    <h2 id="auto-3">2.<span style="margin-left: 1em"></span>An example that minimizes regret cost
    results in a better policy<span style="margin-left: 1em"></span></h2>
    <p>
      Consider the function \(f (x, y)\) as follows:
    </p>
    <center>
      \(\displaystyle \begin{array}{|c|c|c|c|}
  \hline
  &  & x & y\\
 
      \hline
  &  & 0 & 1\\
  \hline
  x & 0 & 100 & 0\\
  \hline
  y & 1 &
      100 & 99\\
  \hline
\end{array} .\)
    </center>
    <p>
      
    </p>
    <p>
      The worst-case cost \(g (x)\) in this example is \(\underset{y}{\max} .
      f (x, y) = f (x, 0) = 100\) for any \(x\). Thus,
    </p>
    <table width="100%">
      <tr>
        <td align="center" width="100%">\(\displaystyle \arg \underset{x}{\min} g (x) = 0
        \vee 1.\)</td>
        <td align="right">(2)</td>
      </tr>
    </table>
    <p>
      But for the worst-case regret cost, \(g' (0) = 0\) and \(g' (1) = 99\).
      Thus
    </p>
    <table width="100%">
      <tr>
        <td align="center" width="100%">\(\displaystyle \arg \underset{x}{\min} g' (x) =
        0.\)</td>
        <td align="right">(3)</td>
      </tr>
    </table>
    <h2 id="auto-4">3.<span style="margin-left: 1em"></span>Data correlation<span style="margin-left: 1em"></span></h2>
    <p>
      The fundamental assumption of standard offline machine learning is that
      the collected data are independently and identically distributed,
      stemming from an unknown distribution [<a href="#bib-vapnik_overview_1999">2</a>]. However, this
      assumption can be easily compromised in the realm of online learning [<a
      href="#bib-shalev-shwartz_online_2011-1">1</a>]. For instance, let's reconsider a scenario involving a
      driver who refrains from driving on rainy days. In this case, data
      points (representing the time taken to travel between places) within a
      one-hour time-frame might have a probability of collection as low as
      \(0\). Conversely, data points beyond one hour might possess a
      probability of collection greater than \(0\). This implies that data
      collected on different dates adhere to distinct distributions. This
      distinction underscores a crucial difference between traditional offline
      learning and online learning.
    </p>
    <h1 id="auto-5">Bibliography<span style="margin-left: 1em"></span></h1>
    <div class="compact-block" style="text-indent: 0em">
      <font style="font-size: 84.0%"><dl>
        <p>
          <dt>
            <strong>[1]  </strong>
          </dt>
          <dd>
            <p>
              <a id="bib-shalev-shwartz_online_2011-1"></a>Shai Shalev-Shwartz. Online Learning and Online
              Convex Optimization. <i>Foundations and Trends in Machine
              Learning</i>, 4(2):107&ndash;194, 2011.
            </p>
          </dd>
        </p>
        <p>
          <dt>
            <strong>[2]  </strong>
          </dt>
          <dd>
            <p>
              <a id="bib-vapnik_overview_1999"></a>V.N. Vapnik. An overview of statistical learning
              theory. <i>IEEE Transactions on Neural Networks</i>,
              10(5):988&ndash;999, sep 1999.
            </p>
          </dd>
        </p>
      </dl></font>
    </div>
    <p>
      
    </p>
  </body>
</html>